开启线程=Ncpu/(1-阻塞系数)=Ncpu*(1+w/c),===》阻塞系数=w/(w+c)，即阻塞系数=阻塞时间/(阻塞时间+计算时间)

总之，如果任务有50%的时间处于阻塞状态，则程序所需线程数为处理器可用核心数的两倍。如果任务被阻塞的时间少于50%，即这些任务是计算密集型的，则程序所需线程数将随之减少，但最少也不应低于处理器的核心数。如果任务被阻塞的时间大于执行时间，即该任务是IO密集型的

这个公式重要
公式：带宽X等待时间/页面大小=并发人数
首先我们计算1M带宽在8S中之内能传送多少个60KB的页面，1024*8/60=136.53也就是大约为137个。这意味着，如果每一个用户都愿意等到极限的8秒钟，那么我们可以满足137个人同时在线。
如果想要每个人平均等1秒钟的话，这个数字大概是17(1024*1/60)。按照这个公式，如果你的服务器是5M带宽的话，它支持的最大并发数是1024*5*8/60=683.也就是5M带宽的服务器支持的最大支持683个人同时在线。


1)带宽问题首先排除，扫过码充其量最多1k数据，对于带宽来说扫过码几万人同时在线随便支持，带宽还杠杠的；
2)单机应用服务器核数，对他们政府来说，至少几十核舍，就打64核，也达128线程；趋向cpu计算型按50ms响应，1秒也是 128 * 1000/50=2560,
  若按IO密集型肯定是2560的倍数，甚至过万；粗略估计10台，不考虑高可用状态下10台服务器绰绰够用，3万同时在线；
3)单机数据库服务器，按阿里公开调优后的 1000 * cpu核数 *( 1到2系数) ，还得考虑单表应<500万记录，
  现在扩容到了16盒64G 连接数14000 iops16000
   
  磁盘io,越堵越慢，越慢越堵,
